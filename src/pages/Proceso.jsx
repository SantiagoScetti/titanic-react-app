import React from 'react';
import './Proceso.css';

function Proceso() {
    return (
        <article className="proceso">
            <header>
                <h1>Mi Proceso de Entrenamiento</h1>
                <p className="intro">
                    Entren√© un modelo de machine learning para predecir la supervivencia de pasajeros del Titanic usando Random Forest. Aqu√≠ te explico c√≥mo lo hice y por qu√© eleg√≠ este m√©todo.
                </p>
            </header>

            <section>
                <h2>¬øPor qu√© Random Forest?</h2>
                <p>
                    Eleg√≠ Random Forest porque es un m√©todo poderoso y flexible que combina muchos √°rboles de decisi√≥n para obtener predicciones m√°s precisas y evitar el sobreajuste. Funciona bien con datos mixtos como los del Titanic (n√∫meros y categor√≠as) y me permiti√≥ analizar qu√© caracter√≠sticas eran m√°s importantes.
                </p>
            </section>

            <section>
                <h2>¬øQu√© es un √Årbol Binario de Decisi√≥n?</h2>
                <p>
                    Un √°rbol binario de decisi√≥n es un modelo que divide los datos en dos ramas en cada paso, bas√°ndose en preguntas como "¬øEs hombre?" o "¬øTiene m√°s de 30 a√±os?". Estas divisiones crean una estructura de √°rbol que termina en una predicci√≥n (sobrevivi√≥ o no). Es √∫til en machine learning porque es simple y visualiza c√≥mo se toman decisiones.
                </p>
                <figure>
                    <img
                        src="/DecisionTree.png"
                        alt="Ejemplo de √Årbol Binario de Decisi√≥n"
                    />
                    <figcaption>Ejemplo de √Årbol Binario de Decisi√≥n</figcaption>
                </figure>
            </section>

            <section>
                <h2>¬øQu√© es un Bosque Aleatorio?</h2>
                <p>
                    Un bosque aleatorio (Random Forest) es un grupo de √°rboles de decisi√≥n. Cada √°rbol se entrena con una muestra aleatoria de los datos y sus predicciones se combinan (por votaci√≥n) para dar un resultado final. Esto lo hace m√°s robusto y preciso que un solo √°rbol.
                </p>

                <div className="ventajas">
                    <h3>Ventajas:</h3>
                    <ul>
                        <li>Reduce el sobreajuste al promediar muchos √°rboles</li>
                        <li>Maneja bien datos complejos y ruidosos</li>
                        <li>Indica la importancia de cada caracter√≠stica (ej: el sexo fue clave en el Titanic)</li>
                    </ul>
                </div>

                <figure>
                    <img
                        src="/Random_Forest_Algorithm.webp"
                        alt="Diagrama de Bosque Aleatorio"
                    />
                    <figcaption>Diagrama del algoritmo Random Forest</figcaption>
                </figure>
            </section>

            <section>
                <h2>C√≥mo Entren√© el Modelo</h2>
                <p>Us√© los datos del Titanic y segu√≠ estos pasos:</p>
                
                <ol>
                    <li>
                        <strong>Exploraci√≥n y Limpieza de Datos:</strong> Primero analic√© el dataset para entender qu√© informaci√≥n ten√≠a. Elimin√© columnas que no aportaban valor predictivo y manej√© los datos faltantes. Tambi√©n cre√© nuevas caracter√≠sticas m√°s √∫tiles para el modelo.
                    </li>
                    <li>
                        <strong>Ingenier√≠a de Caracter√≠sticas:</strong> Transform√© los datos originales para que el modelo pudiera aprender mejor:
                        <ul className="transformaciones">
                            <li><strong>Tama√±o de Familia:</strong> Combin√© las columnas de hermanos/c√≥nyuges y padres/hijos para crear una variable que represente el tama√±o total de la familia viajando junta.</li>
                            <li><strong>Grupos de Familia:</strong> Clasifiqu√© a los pasajeros en categor√≠as como "Solo", "Familia Peque√±a", "Familia Mediana" y "Familia Grande", ya que estos grupos podr√≠an tener diferentes tasas de supervivencia.</li>
                            <li><strong>Rangos de Edad:</strong> Divid√≠ las edades en grupos m√°s significativos en lugar de usar n√∫meros exactos, lo que ayuda al modelo a encontrar patrones m√°s claros.</li>
                            <li><strong>T√≠tulos de Cortes√≠a:</strong> Extraje t√≠tulos como "Mr.", "Mrs.", "Miss" de los nombres, ya que revelan informaci√≥n sobre g√©nero, estado civil y estatus social.</li>
                        </ul>
                    </li>
                    <li>
                        <strong>Divisi√≥n de Datos:</strong> Separ√© los datos en entrenamiento (80%) y validaci√≥n (20%) usando estratificaci√≥n para mantener la misma proporci√≥n de sobrevivientes en ambos conjuntos.
                    </li>
                    <li>
                        <strong>Preprocesamiento:</strong> Us√© pipelines para tratar autom√°ticamente los datos categ√≥ricos (con codificaci√≥n ordinal y one-hot) y num√©ricos (rellenando valores faltantes con medianas).
                    </li>
                    <li>
                        <strong>Optimizaci√≥n del Modelo:</strong> Configur√© un RandomForestClassifier y us√© GridSearchCV para probar diferentes combinaciones de par√°metros y encontrar la configuraci√≥n √≥ptima.
                    </li>
                    <li>
                        <strong>Entrenamiento Final:</strong> Entren√© el modelo con los mejores par√°metros encontrados usando todos los datos preprocesados.
                    </li>
                </ol>
            </section>

            <section>
                <h2>Explicaci√≥n de los par√°metros del Random Forest</h2>
                <p>Para que el Random Forest funcione bien, necesit√© ajustar varios par√°metros. Aqu√≠ te explico qu√© hace cada uno:</p>
                
                <div>
                    <div>
                        <h3>üå≥ n_estimators: 300</h3>
                        <p><strong>¬øQu√© es?</strong> La cantidad de √°rboles en el bosque.</p>
                        <p><strong>Analog√≠a:</strong> Imagina que necesitas tomar una decisi√≥n importante. ¬øPrefieres la opini√≥n de 1 persona o de 300 personas expertas?</p>
                        <p><strong>En el modelo:</strong> M√°s √°rboles = predicciones m√°s estables, pero tambi√©n m√°s tiempo de entrenamiento. 300 fue el punto √≥ptimo. Cuando se aument√≥ la cantidad en 500 la presici√≥n del modelo baj√≥. M√°s √°rboles pueden hacer que el modelo capture m√°s ruido en los datos, especialmente si el conjunto de datos es peque√±o o tiene muchas caracter√≠sticas irrelevantes. Esto reduce la generalizaci√≥n y, por ende, la precisi√≥n en datos de prueba</p>
                    </div>

                    <div>
                        <h3>üìè max_depth: 15</h3>
                        <p><strong>¬øQu√© es?</strong> La profundidad m√°xima que puede tener cada √°rbol.</p>
                        <p><strong>Analog√≠a:</strong> Es como limitar cu√°ntas preguntas seguidas puede hacer cada √°rbol. "¬øEs mujer?" ‚Üí "¬øTiene menos de 30 a√±os?" ‚Üí "¬øViaja en primera clase?" ‚Üí etc.</p>
                        <p><strong>En el modelo:</strong> 15 niveles permiten capturar patrones complejos sin memorizar datos espec√≠ficos (sobreajuste).</p>
                    </div>

                    <div>
                        <h3>üçÉ min_samples_leaf: 6</h3>
                        <p><strong>¬øQu√© es?</strong> El n√∫mero m√≠nimo de personas que debe haber en cada "hoja" del √°rbol.</p>
                        <p><strong>Analog√≠a:</strong> No puedes hacer una regla bas√°ndote en muy pocas personas. Es como decir "necesito al menos 6 casos similares para estar seguro de mi predicci√≥n".</p>
                        <p><strong>En el modelo:</strong> Evita que el √°rbol haga predicciones basadas en casos muy espec√≠ficos o raros.</p>
                    </div>

                    <div>
                        <h3>üîÄ min_samples_split: 10</h3>
                        <p><strong>¬øQu√© es?</strong> El n√∫mero m√≠nimo de personas necesarias para dividir un grupo en dos.</p>
                        <p><strong>Analog√≠a:</strong> No vale la pena hacer una nueva pregunta si solo tienes 5 personas. Mejor esperar a tener al menos 10 para que la divisi√≥n tenga sentido.</p>
                        <p><strong>En el modelo:</strong> Evita divisiones innecesarias cuando hay pocos datos.</p>
                    </div>

                    <div>
                        <h3>‚öñÔ∏è criterion: "gini"</h3>
                        <p><strong>¬øQu√© es?</strong> La f√≥rmula que usa cada √°rbol para decidir cu√°l es la mejor pregunta.</p>
                        <p><strong>Analog√≠a:</strong> Es como tener una regla para elegir la pregunta que mejor separe a los sobrevivientes de los que no sobrevivieron.</p>
                        <p><strong>En el modelo:</strong> "Gini" mide qu√© tan "puro" queda cada grupo despu√©s de hacer una pregunta. Prefiere preguntas que dejen grupos m√°s homog√©neos.</p>
                    </div>
                </div>
            </section>

            <section className="resultados">
                <h2>En resumen</h2>
                <p>Los mejores par√°metros encontrados fueron:</p>

                <pre>
                    <code>{`{
    criterion: "gini",
    max_depth: 15,
    min_samples_leaf: 6,
    min_samples_split: 10,
    n_estimators: 300
}`}
                    </code>
                </pre>

                <p>
                    Con estos par√°metros, el modelo logr√≥ una <strong>precisi√≥n del 82.44%</strong> en los datos de validaci√≥n.
                </p>

                <figure>
                    <img
                        src="/precicionnroarboles.png"
                        alt="Gr√°fico de Precisi√≥n vs. N√∫mero de √Årboles"
                    />
                    <figcaption>Precisi√≥n vs. N√∫mero de √Årboles</figcaption>
                </figure>
            </section>
        </article>
    );
}

export default Proceso;